{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().magic('load_ext autoreload')\n",
    "    get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import cv2\n",
    "\n",
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"/tmp/caiman.log\",\n",
    "                    level=logging.INFO)\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf as cnmf\n",
    "from caiman.paths import caiman_datadir\n",
    "from caiman.utils.utils import download_demo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "try:\n",
    "       from bokeh.io import vform, hplot\n",
    "except:\n",
    "       # newer version of bokeh does not use vform & hplot, instead uses column & row\n",
    "       from bokeh.layouts import column as vform\n",
    "       from bokeh.layouts import row as hplot\n",
    "from bokeh.models import CustomJS, ColumnDataSource, Slider\n",
    "\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select file(s) to be processed\n",
    "The `download_demo` function will download the specific file for you and return the complete path to the file which will be stored in your `caiman_data` directory. If you adapt this demo for your data make sure to pass the complete path to your file(s). Remember to pass the `fnames` variable as a list. Note that the memory requirement of the CNMF-E algorithm are much higher compared to the standard CNMF algorithm. Test the limits of your system before trying to process very large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['data_endoscope.tif']  # filename to be processed\n",
    "fnames = [download_demo(fnames[0])]\n",
    "fnames = ['/Users/epnevmatikakis/Documents/Ca_datasets/Miniscope/msCam13.avi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fr = 10                          # movie frame rate\n",
    "decay_time = 0.4                 # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "motion_correct = True            # flag for performing motion correction\n",
    "pw_rigid = False                 # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "gSig_filt = (7, 7)               # size of high pass spatial filtering, used in 1p data\n",
    "max_shifts = (15, 15)            # maximum allowed rigid shift\n",
    "strides = (96, 96)               # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)              # overlap between pathes (size of patch strides+overlaps)\n",
    "max_deviation_rigid = 5          # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'              # replicate values along the boundaries\n",
    "\n",
    "mc_dict = {\n",
    "    'decay_time': decay_time,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan\n",
    "}\n",
    "\n",
    "\n",
    "rf = 48\n",
    "stride = 8\n",
    "ssub = 1\n",
    "ds_factor = 4*ssub\n",
    "\n",
    "gSig = (12//ds_factor, 12//ds_factor)            # expected half size of neurons\n",
    "gSiz = (36//ds_factor, 36//ds_factor)\n",
    "p = 0                                          # order of AR indicator dynamics\n",
    "min_SNR = 1.5                                  # minimum SNR for accepting new components\n",
    "min_pnr = 10                                   # minimum PNR during cnmf-E initialization\n",
    "min_corr = 0.8                                 # minimum corr image value during cnmf-E initialization\n",
    "rval_thr = 0.85                                # correlation threshold for new component inclusion\n",
    "sniper_mode = False                            # flag using a CNN to detect new neurons (o/w space correlation is used)\n",
    "init_batch = 300                               # number of frames for initialization (presumably from the first file)\n",
    "expected_comps = 500                           # maximum number of expected components used for memory pre-allocation (exaggerate here)\n",
    "dist_shape_update = False                      # flag for updating shapes in a distributed way\n",
    "min_num_trial = 8                              # number of candidate components per frame     \n",
    "K = None                                       # initial number of components\n",
    "epochs = 2                                     # number of passes over the data\n",
    "show_movie = False                             # show the movie with the results as the data gets processed\n",
    "\n",
    "cnmfe_dict = {'fnames': fnames,\n",
    "              'fr': fr,\n",
    "              'decay_time': decay_time,\n",
    "              'method_init': 'corr_pnr',\n",
    "              'gSig': gSig,\n",
    "              'gSiz': gSiz,\n",
    "              'rf': rf,\n",
    "              'stride': stride,\n",
    "              'p': p,\n",
    "              'epochs': 2,\n",
    "              'nb': 0,\n",
    "              'ssub': ssub,\n",
    "              'ds_factor': ds_factor,                                   # ds_factor >= ssub should hold\n",
    "              'min_SNR': min_SNR,\n",
    "              'min_pnr': min_pnr,\n",
    "              'min_corr': min_corr,\n",
    "              'bas_nonneg': False,\n",
    "              'center_psf': True,\n",
    "              'rval_thr': rval_thr,\n",
    "              'init_batch': init_batch,\n",
    "              'only_init': True,\n",
    "              'init_method': 'cnmf',\n",
    "              'normalize_init': False,\n",
    "              'update_freq': 200,\n",
    "              'expected_comps': expected_comps,\n",
    "              'sniper_mode': sniper_mode,\n",
    "              'dist_shape_update' : dist_shape_update,\n",
    "              'min_num_trial': min_num_trial,\n",
    "              'merge_thr': 0.65,\n",
    "              'K': K,\n",
    "              'epochs': epochs,\n",
    "              'show_movie': show_movie}\n",
    "opts = cnmf.params.CNMFParams(gnb=0, params_dict={**mc_dict, **cnmfe_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gSiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnm = cnmf.online_cnmf.OnACID(params=opts, dview=dview)\n",
    "cnm.fit_online()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = cm.load(fnames[0], subindices=slice(0,1000))\n",
    "Cn, pnr = cm.summary_images.correlation_pnr(images[::1], gSig=gSig[0], swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "cnm.estimates.nb_view_components(img=Cn, denoised_color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.plot_contours_nb(img=Cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnm.estimates.plot_contours(img=Cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot timing\n",
    "The plot below shows the time spent on each part of the algorithm (motion correction, tracking of current components, detect new components, update shapes) for each frame. Note that if you displayed a movie while processing the data (`show_movie=True`) the time required to generate this movie will be included here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T_motion = 1e3*np.array(cnm.t_motion)\n",
    "T_detect = 1e3*np.array(cnm.t_detect)\n",
    "T_shapes = 1e3*np.array(cnm.t_shapes)\n",
    "T_online = 1e3*np.array(cnm.t_online) - T_motion - T_detect - T_shapes\n",
    "plt.figure()\n",
    "plt.stackplot(np.arange(len(T_motion)), T_motion, T_online, T_detect, T_shapes)\n",
    "plt.legend(labels=['motion', 'process', 'detect', 'shapes'], loc=2)\n",
    "plt.title('Processing time allocation')\n",
    "plt.xlabel('Frame #')\n",
    "plt.ylabel('Processing time [ms]')\n",
    "plt.ylim([0, 1.2e3*np.percentile(np.array(cnm.t_online), 90)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.play_movie(images, magnification=1, q_max=99.5, q_min=0.5, include_bck=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
