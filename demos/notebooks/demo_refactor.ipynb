{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if __IPYTHON__:\n",
    "        # this is used for debugging purposes only. allows to reload classes when changed\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import glob\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import cv2\n",
    "\n",
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"/tmp/caiman.log\",\n",
    "                    level=logging.INFO)\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf as cnmf\n",
    "from caiman.paths import caiman_datadir\n",
    "from caiman.utils.utils import download_demo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "try:\n",
    "       from bokeh.io import vform, hplot\n",
    "except:\n",
    "       # newer version of bokeh does not use vform & hplot, instead uses column & row\n",
    "       from bokeh.layouts import column as vform\n",
    "       from bokeh.layouts import row as hplot\n",
    "from bokeh.models import CustomJS, ColumnDataSource, Slider\n",
    "\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select file(s) to be processed\n",
    "The `download_demo` function will download the specific file for you and return the complete path to the file which will be stored in your `caiman_data` directory. If you adapt this demo for your data make sure to pass the complete path to your file(s). Remember to pass the `fnames` variable as a list. Note that the memory requirement of the CNMF-E algorithm are much higher compared to the standard CNMF algorithm. Test the limits of your system before trying to process very large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['data_endoscope.tif']  # filename to be processed\n",
    "fnames = [download_demo(fnames[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fr = 15                                                             # frame rate (Hz)\n",
    "decay_time = 0.95                                                   # approximate length of transient event in seconds\n",
    "gSig = (3, 3)                                                       # expected half size of neurons\n",
    "gSiz = (13, 13)\n",
    "ssub = 1\n",
    "ds_factor = ssub\n",
    "p = 0                                                               # order of AR indicator dynamics\n",
    "min_SNR = 1.5                                                       # minimum SNR for accepting new components\n",
    "min_pnr = 10\n",
    "min_corr = 0.8\n",
    "rval_thr = 0.85                                                     # correlation threshold for new component inclusion\n",
    "mot_corr = True                                                     # flag for online motion correction \n",
    "pw_rigid = False                                                    # flag for pw-rigid motion correction (slower but potentially more accurate)\n",
    "max_shifts_online = 10                                              # maximum allowed shift during motion correction\n",
    "sniper_mode = False                                                 # flag using a CNN to detect new neurons (o/w space correlation is used)\n",
    "init_batch = 300                                                    # number of frames for initialization (presumably from the first file)\n",
    "expected_comps = 500                                                # maximum number of expected components used for memory pre-allocation (exaggerate here)\n",
    "dist_shape_update = False                                           # flag for updating shapes in a distributed way\n",
    "min_num_trial = 8                                                   # number of candidate components per frame     \n",
    "K = None                                                            # initial number of components\n",
    "epochs = 2                                                          # number of passes over the data\n",
    "show_movie = False                                                  # show the movie with the results as the data gets processed\n",
    "\n",
    "params_dict = {'fnames': fnames,\n",
    "               'fr': fr,\n",
    "               'decay_time': decay_time,\n",
    "               'method_init': 'corr_pnr',\n",
    "               'gSig': gSig,\n",
    "               'gSiz': gSiz,\n",
    "               'p': p,\n",
    "               'epochs': 2,\n",
    "               'ssub': ssub,\n",
    "               'ds_factor': ssub,                                   # important to have ds_factor = ssub\n",
    "               'min_SNR': min_SNR,\n",
    "               'min_pnr': min_pnr,\n",
    "               'min_corr': min_corr,\n",
    "               'bas_nonneg': True,\n",
    "               'center_psf': True,\n",
    "               'rval_thr': rval_thr,\n",
    "               'motion_correct': mot_corr,\n",
    "               'init_batch': init_batch,\n",
    "               'only_init': True,\n",
    "               'init_method': 'cnmf',\n",
    "               'normalize_init': False,\n",
    "               'update_freq': 200,\n",
    "               'expected_comps': expected_comps,\n",
    "               'sniper_mode': sniper_mode,\n",
    "               'dist_shape_update' : dist_shape_update,\n",
    "               'min_num_trial': min_num_trial,\n",
    "               'merge_thr': 0.65,\n",
    "               'K': K,\n",
    "               'epochs': epochs,\n",
    "               'max_shifts_online': max_shifts_online,\n",
    "               'pw_rigid': pw_rigid,\n",
    "               'show_movie': show_movie}\n",
    "opts = cnmf.params.CNMFParams(gnb=0, params_dict=params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnm = cnmf.online_cnmf.OnACID(params=opts)\n",
    "cnm.fit_online()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = cm.load(fnames[0], subindices=slice(0,1000))\n",
    "Cn, pnr = cm.summary_images.correlation_pnr(images[::1], gSig=gSig[0], swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "cnm.estimates.nb_view_components(img=Cn, denoised_color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.plot_contours_nb(img=Cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnm.estimates.plot_contours(img=Cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot timing\n",
    "The plot below shows the time spent on each part of the algorithm (motion correction, tracking of current components, detect new components, update shapes) for each frame. Note that if you displayed a movie while processing the data (`show_movie=True`) the time required to generate this movie will be included here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "T_motion = 1e3*np.array(cnm.t_motion)\n",
    "T_detect = 1e3*np.array(cnm.t_detect)\n",
    "T_shapes = 1e3*np.array(cnm.t_shapes)\n",
    "T_online = 1e3*np.array(cnm.t_online) - T_motion - T_detect - T_shapes\n",
    "plt.figure()\n",
    "plt.stackplot(np.arange(len(T_motion)), T_motion, T_online, T_detect, T_shapes)\n",
    "plt.legend(labels=['motion', 'process', 'detect', 'shapes'], loc=2)\n",
    "plt.title('Processing time allocation')\n",
    "plt.xlabel('Frame #')\n",
    "plt.ylabel('Processing time [ms]')\n",
    "plt.ylim([0,140]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.play_movie(images, magnification=3, q_max=99.5, q_min=0.5, include_bck=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
